services:
  client-consumer:
    image: client-consumer:0.0.1
    build:
      context: .
      dockerfile: consumer/Dockerfile
    ports:
      - "8082:8082"
    depends_on:
      service-db:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      - SERVER_PORT= 8082
      - SPRING_KAFKA_BOOTSTRAP-SERVERS=kafka:9092
      - SPRING_DATASOURCE_URL=jdbc:postgresql://service-db/kafka_db

  client-producer:
    image: client-producer:0.0.1
    build:
      context: .
      dockerfile: producer/Dockerfile
    ports:
      - "8081:8081"
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - SERVER_PORT= 8081
      - SPRING_KAFKA_BOOTSTRAP-SERVERS=kafka:9092

  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.4
    healthcheck:
      test: [ "CMD", "nc", "-vz", "localhost", "2181" ]
      interval: 10s
      timeout: 3s
      retries: 3
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - 22181:2181

  kafka:
    image: confluentinc/cp-kafka:6.2.4
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - 29092:29092
    healthcheck:
      test: [ "CMD", "nc", "-vz", "localhost", "9092" ]
      interval: 10s
      timeout: 3s
      retries: 3
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: OUTSIDE://:29092,INTERNAL://:9092
      KAFKA_ADVERTISED_LISTENERS: OUTSIDE://localhost:29092,INTERNAL://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka-ui:
    image: provectuslabs/kafka-ui
    container_name: kafka-ui
    ports:
      - "8080:8080"
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092

  service-db:
    image: postgres:14.7-alpine
    environment:
      POSTGRES_USER: username
      POSTGRES_PASSWORD: password
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready", "-d", "kafka_db" ]
      interval: 10s
      timeout: 3s
      retries: 3
    ports:
      - "15432:5432"
    volumes:
      - ./infrastructure/db/db_creation.sql:/docker-entrypoint-initdb.d/db_creation.sql
    command:
      - "postgres"
      - "-c"
      - "wal_level=logical"

    restart: unless-stopped

  pgadmin:
    container_name: pgadmin4_container
    image: dpage/pgadmin4:7
    restart: always
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: root
    ports:
      - "5050:80"

  kafka-topics-generator:
    image: confluentinc/cp-kafka:6.2.4
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:9092 --list
      
      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic create.client --replication-factor 1 --partitions 5
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic create.transaction --replication-factor 1 --partitions 5
      
      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:9092 --list
      "
  schema-registry:
    image: confluentinc/cp-schema-registry:6.2.4
    container_name: schema-registry
    depends_on:
      - kafka
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:9092

  kafka-connect:
    image: debezium/connect:1.9
    container_name: kafka-connect
    depends_on:
      - kafka
      - schema-registry
    ports:
      - 8083:8083
    healthcheck:
      test: [ "CMD", "curl", "-f", "kafka-connect:8083/connectors" ]
      interval: 10s
      timeout: 3s
      retries: 3
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: kafka-connect
      CONFIG_STORAGE_TOPIC: connect_configs
      OFFSET_STORAGE_TOPIC: connect_offsets
      KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081

  config-connector:
    image: debezium/connect:1.9
    depends_on:
      kafka-connect:
        condition: service_healthy
    volumes:
      - ./kafka.connector.config.json:/kafka/kafka.connector.config.json
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      " echo -e 'Creating Data Generator source'
            curl -H 'Content-Type: application/json' kafka-connect:8083/connectors --data @kafka.connector.config.json
      "